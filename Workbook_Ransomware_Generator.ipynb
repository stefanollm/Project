{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Panoramica\n",
    "Il presente workshop è stato progettato per introdurti alla Generative AI e per sensibilizzarti su come utenti malintenzionati potrebbero utilizzare questo strumento per scopi malevoli. Attraverso una serie di esercizi pratici, esploreremo come utilizzare la Generative AI per simulare la creazione e l'esecuzione di un ransowmare. Ciascun esercizio è stato strutturato per potenziare la comprensione e le abilità pratiche nel prompt engineering. Questa simulazione verrà eseguita attraverso l'utilizzo del modello di OpenAI ed il framework LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Cosa è OpenAI?\n",
    "OpenAI è un'organizzazione di ricerca sull'intelligenza artificiale (IA) fondata nel dicembre 2015 da Elon Musk, Sam Altman e altri, con l'obiettivo di promuovere e sviluppare intelligenza artificiale. OpenAI si concentra su una varietà di aree di ricerca nell'IA, tra cui l'apprendimento profondo, l'apprendimento per rinforzo, e la comprensione del linguaggio naturale. È nota per il suo lavoro su modelli di linguaggio avanzati come GPT (Generative Pre-trained Transformer), che sono in grado di generare testo, rispondere a domande, sommare informazioni e molto altro, con applicazioni che vanno dallo sviluppo di assistenti virtuali all'analisi e generazione di testi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Cosa è LangChain?\n",
    "LangChain è un framework che mette a disposizione librerie per lo sviluppo di applicazioni che sfruttano l'intelligenza artificiale linguistica, in particolare modelli di linguaggio avanzati come GPT di OpenAI. È progettata per facilitare l'integrazione di capacità di comprensione e generazione del linguaggio naturale nelle applicazioni, permettendo agli sviluppatori di creare soluzioni innovative che vanno dal miglioramento di interfacce utente conversazionali fino alla creazione di sistemi complessi di elaborazione del linguaggio. LangChain offre strumenti e componenti pre-costruiti per semplificare l'utilizzo dei modelli di linguaggio, gestire il flusso di lavoro dell'informazione e migliorare l'interazione tra l'utente e l'IA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Obiettivi\n",
    "Al termine di questo workshop, l'utente sarà in grado di comprendere il funzionamento dei ransomware e simulare le loro funzioni principali per scopi educativi. Questo utilizzando esclusivamente la Generative AI, senza scrivere direttamente il codice. L'obiettivo è aumentare la consapevolezza sulla sicurezza informatica e promuovere la difesa contro minacce informatiche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Disclaimer\n",
    "* Per la realizzazione di questo notebook è stato utilizzato il più recente modello GPT-4 Turbo, i cui Training Data risalgono fino a dicembre 2023 e consente una finestra di contesto fino a 128.000 token. Si prega di notare che l'utilizzo di un modello alternativo e/o con prestazioni differenti potrebbe non garantire gli stessi risultati. Si specifica che alla prima registrazione, OpenAI offre all'utente 5$ in omaggio utilizzabili per il modello GPT3.5 (gpt-3.5-turbo). Gli stessi sono sufficienti per eseguire il workshop, ma non garantiscono le stesse prestazioni.\n",
    "\n",
    "* I modelli GPT (Generative Pre-trained Transformer) sono progettati per comprendere e rispondere a domande in molteplici lingue, tra cui l'inglese e l'italiano. Tuttavia, è vero che la qualità delle risposte può variare a seconda della lingua utilizzata, principalmente a causa della quantità e della varietà dei dati di addestramento disponibili. L'inglese, essendo una delle lingue più comunemente usate online e nei dati di addestramento di molti modelli di intelligenza artificiale, tende a produrre risposte più precise e dettagliate, poiché il modello ha avuto accesso a una quantità maggiore di informazioni durante la fase di addestramento.\n",
    "\n",
    "* Quando si utilizzano i modelli GPT di OpenAI, è fondamentale ricordare che le loro risposte possono variare a causa della non deterministicità intrinseca nel processo di generazione del testo. Questo significa che, presentando la stessa richiesta al modello più volte, si potrebbero ottenere risultati differenti in occasioni diverse. Tale variabilità è dovuta al modo in cui i modelli GPT esplorano e selezionano le possibili risposte da un vasto spazio di opzioni, basandosi su probabilità e contesto. Pertanto, è consigliabile interpretare le risposte fornite dai modelli GPT con un approccio critico e considerarle come una delle molteplici prospettive possibili, piuttosto che come soluzioni definitive o esatte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Architettura Progetto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project/**\\\n",
    "║ \\\n",
    "╠══ **Malicious_Server/**\\\n",
    "║&ensp;&ensp;&ensp;&ensp;&ensp;║\\\n",
    "║&ensp;&ensp;&ensp;&ensp;&ensp;╚══*Server.py*\\\n",
    "║&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;```- File Python che istanzia un server FTP per il controllo del sistema di attacco.```\\\n",
    "║\\\n",
    "╠══ **Target/**\\\n",
    "║&ensp;&ensp;&ensp;&ensp;&ensp;║\\\n",
    "║&ensp;&ensp;&ensp;&ensp;&ensp;╚══**Documents/**\\\n",
    "║&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;║\\\n",
    "║&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;╠══*employees_personal_info.rtf*\\\n",
    "║&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;╠══*wallet_bitcoin.txt*\\\n",
    "║&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;║&ensp;&ensp;&ensp;&ensp;```- File generati da 'Folder_Generator.py'```\\\n",
    "║&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;╚══*Ransomware.py*\\\n",
    "║&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;```- Viene generato durante dell'Esercizio 1 di 'Workbook_Ransomware_generator.ipynb'.```\\\n",
    "║&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;```- Viene aggiornato iterativamente con gli esercizi successivi.```\\\n",
    "║\\\n",
    "╠══ **Utilities/**\\\n",
    "║&ensp;&ensp;&ensp;&ensp;&ensp;║\\\n",
    "║&ensp;&ensp;&ensp;&ensp;&ensp;╚══*Folder_Generator.py*\\\n",
    "║&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;```- File Python che:```\\\n",
    "║&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;```- Crea la cartella 'Documents' per simulare il sistema della vittima.```\\\n",
    "║&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;&ensp;```- Svuota la cartella 'Malicious_Server', ad eccezione del file 'Server.py'.```\\\n",
    "║\\\n",
    "╚══  *Workbook_Ransomware_generator.ipynb*:\\\n",
    "&ensp;&ensp;&ensp;&ensp;&ensp;```- Notebook contenente gli esercizi da svolgere durante il workshop.```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Installazione ambiente di sviluppo\n",
    "Un Ambiente di Sviluppo Integrato (IDE) è cruciale per programmare in modo efficiente, fornendo funzionalità come l'editing del codice, la gestione dei progetti e il debugging in un unico strumento. Il nostro consiglio è di approcciarsi a questo notebook attraverso l'utilizzo di **Visual Studio Code**\n",
    " scaricabile attraverso il Microsoft Store.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Installazione Python\n",
    "Per utilizzare le librerie Python di OpenAI e LangChain, è necessario assicurarsi di avere **Python** installato correttamente sul proprio sistema. Alcuni Sistemi Operativi già prevedono l'installazione di Python, mentre su altri è necessario configurarlo manualmente. Per verificarne l'installazione, puoi accedere al Terminale o alla riga di comando (su Windows, puoi trovarlo cercando \"cmd\" nel menu Start), quindi digitare \"*python*\" e premere Invio. Se viene visualizzato l'interprete Python, significa che è già installato sul tuo computer. Al contrario, se ricevi un messaggio di errore, dovrai probabilmente procedere con l'installazione di Python attraverso il Microsoft Store o dal sito ufficiale[https://www.python.org/downloads/] e renderlo disponibile nel tuo terminale/riga di comando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Setup ambiente Visual Studio Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Import progetto e Creazione ambiente virtuale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Import progetto:\n",
    "    * ```File -> Open Folder -> Project ```\n",
    "\n",
    "* Creazione ambiente virtuale (fornisce uno spazio di lavoro pulito per l'installazione dei pacchetti Python in modo da non avere conflitti con altre librerie installate per altri progetti):\n",
    "    * ```Terminal -> New Terminal```\n",
    "    * ```python -m venv venv```\n",
    "    * ```.\\\\venv\\Scripts\\activate```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qualora riscontrassi errori del tipo:\n",
    "\n",
    "```\n",
    ".\\\\venv\\Scripts\\activate : Impossibile caricare il file C:\\Users\\User\\Desktop\\ransomware\\venv\\Scripts\\Activate.ps1. L'esecuzione di script è disabilitata nel sistema in uso. Per ulteriori informazioni, vedere about_Execution_Policies all'indirizzo\n",
    "https://go.microsoft.com/fwlink/?LinkID=135170.\n",
    "In riga:1 car:1\n",
    "```\n",
    "\n",
    "Sarà necessario disabilitare i criteri di restrizione di PowerShell ed impostare i criteri di esecuzione su Senza restrizioni. Questo sarà possibile effettuarlo attraverso i seguenti passaggi:\n",
    "\n",
    "- Esegui come amministratore PowerShell\n",
    "- digita ```Set-ExecutionPolicy Unrestricted```\n",
    "- digita ```s```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Installazione dei Pacchetti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una volta installato Python e configurato un ambiente virtuale, è possibile installare le librerie necessarie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo notebook richiede l'installazione di diversi pacchetti Python, tra cui:\n",
    "- **openai** fornisce un comodo accesso all'API OpenAI, consentendo di utilizzare le funzionalità offerte dalla piattaforma OpenAI.\n",
    "- **langchain** è una libreria che semplifica la creazione di applicazioni basate su LLM.\n",
    "- **langchain-openai** è un'estensione del pacchetto LangChain che integra specificamente le funzionalità di OpenAI.\n",
    "- **ipykernel** pacchetto Python che fornisce il kernel per Jupyter, permettendo a Jupyter Notebook / JupyterLab o Visual Studio di eseguire codice Python. \n",
    "- **pyftpdlib** Una libreria Python per creare server FTP facilmente.\n",
    "- **cryptography** Un pacchetto Python per crittografia e sicurezza dei dati.\n",
    "- **tk** Toolkit GUI di Python per creare interfacce utente grafiche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si prega di eseguire da terminale (in ambiente virtuale) il comando sottostante. Esso, contiene i comandi essenziali per l'installazione di tutti i pacchetti Python necessari per eseguire il notebook in modo corretto. Questo passaggio è fondamentale per l'esecuzione di qualsiasi altra parte del notebook. \n",
    "\n",
    "```pip install openai langchain langchain-openai ipykernel pyftpdlib cryptography tk ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B. Visual studio potrebbe richiedere di installare dipendenze suggerite. Inoltre, alla richiesta di selezione del Kernel, fare click su Python Evironments e successivamente selezionare il virtual enviroment precedentemente nominato *venv*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Import delle Librerie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il blocco seguente contiene tutte le librerie e i moduli necessari per eseguire correttamente il notebook. Prima di procedere con l'esecuzione degli altri blocchi, assicurati prima di aver eseguito correttamente questo per evitare eventuali errori durante l'esecuzione del codice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import platform\n",
    "\n",
    "# Imports Langchain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate\n",
    ")\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "from langchain.callbacks import get_openai_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Integrazione con OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Configurazione della chiave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se non disponi di una chiave API OpenAI, puoi ottenerne una da [https://platform.openai.com/account/api-keys]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una volta ottenuta la chiave, aggiungila alle variabili di ambiente come OPENAI_API_KEY eseguendo il seguente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"INSERISCI_QUI_LA_TUA_API_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Definizione del modello"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI mette a disposizione una vasta selezione di modelli con vari livelli di potenza, ognuno adatto a specifici compiti. Per consultare tutti i modelli offerti da OpenAI, è possibile fare riferimento al seguente link: https://platform.openai.com/docs/models. \n",
    "\n",
    "Per questo notebook è stato utilizzato il più recente modello GPT-4 Turbo come segue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = \"gpt-4-turbo-preview\" # utilizzo del modello gpt4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Integrazione con LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Definizione del Chat Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La successiva cella di codice consente di definire l'istanza dell'oggetto **ChatOpenAI**, il quale rappresenta un componente essenziale di LangChain, che fornisce la capacità di interagire con i modelli di chat di OpenAI. I modelli di chat di OpenAI sono progettati per generare risposte testuali simulando una conversazione umana. I modelli di chat accettano un elenco di messaggi come input e restituiscono un messaggio generato dal modello come output. ```(Sebbene il formato della chat sia progettato per semplificare le conversazioni a più turni, è altrettanto utile per le attività a turno singolo senza alcuna conversazione. SI PUò TOGLIERE)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All'interno dell'oggetto ChatOpenAI è possibile specificare diversi parametri, uno tra questi è la temperatura. La **temperature** è un parametro con valore compreso tra 0 e 2, che controlla la creatività e la casualità delle risposte del modello. Valori alti rendono le risposte più creative ma meno precise, mentre valori bassi le rendono più precise ma meno creative. Qui è impostata a 0 per risposte precise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=llm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Definizione del Prompt Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un passaggio fondamentale consiste nella corretta configurazione del prompt. Utilizzeremo la classe **ChatPromptTemplate** di seguito, per definire il prompt della chat.\n",
    "Un ChatPromptTemplate è un componente di LangChain utilizzato per creare modelli di prompt che siano flessibili e adatti ai vari contesti delle chat.\n",
    "Attraverso questo strumento, diventa possibile definire una sequenza di messaggi di chat, ciascuno associato a ruoli specifici quali System, Human e AI.\n",
    "- Il *SystemMessage* è un messaggio persistente che aiuta a impostare il comportamento dell'assistente. Ad esempio, puoi modificare la personalità dell'assistente o fornire istruzioni specifiche su come dovrebbe comportarsi durante la conversazione.\n",
    "- Gli *HumanMessage* rappresenta un messaggio da parte dell'utente a cui l'assistente può rispondere.\n",
    "- L'*AIMessage* rappresenta un messaggio generato dall'IA durante l'interazione. Utilizzeremo questo componente per integrare nei prompt che si suggeguono la risposta immediatamente precedente ricevuta dal modello. Includere questo messaggio è fondamentale per garantire il corretto svolgimento di questo notebook. Quest'ultimo infatti è strutturato in modo incrementale, dove ogni esercizio dipende dal corretto completamento di quelli precedenti. Pertanto, questo messaggio è cruciale quando le istruzioni dell'utente fanno riferimento alla risposta precedentemente fornita dal modello.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_messages = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=\"\"\"You are a helpful assistant programmed to generate a Python program based on the \n",
    "Human's request. Based on the request you will have to update the code provided by the AI \n",
    "by integrating the new features. Your approach must prioritize augmenting existing code, \n",
    "ensuring progressive evolution of the program delivered by AI. You must generate only Python code.\n",
    "\"\"\"\n",
    "        ),  # Il messaggio di sistema persistente\n",
    "        AIMessagePromptTemplate.from_template(\n",
    "            \"\\n{ai_input}\\n\"\n",
    "        ),  # Dove verrà inserito l'input dell'AI   \n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"{human_input}\"\n",
    "        ),  # Dove verrà inserito l'input dell'utente\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Definizione della Catena"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il passaggio successivo implica la definizione della Catena. Come suggerisce il nome, le catene sono il fulcro dei workflow di LangChain. Uniscono gli LLM ad altri componenti, creando applicazioni mediante l'esecuzione di una sequenza di funzioni.\n",
    "La catena che verrà utilizzata in questo notebook è **LLMChain**. Attraverso il blocco di codice successivo, definiamo una LLMChain che ha il compito di ricevere l'input dell'utente, formattarlo utilizzando un *ChatPromptTemplate* e, in seguito, passare questa risposta formattata all'LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizziamo l'opzione **verbose=True** per abilitare la visualizzazione dettagliata delle informazioni durante l'esecuzione della catena. Questo parametro fornisce output aggiuntivo e informativo sulle attività in corso, utile per il monitoraggio e il debugging del processo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=template_messages,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Crea il tuo Ransomware"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.0 Prerequisiti\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per simulare un sistema di Command & Control, per questo workshop è stato predisposto un file Python chiamato '*Server.py*' all'interno della cartella '*Malicious_Server*'. Questo script:\n",
    "- istanzia un Server FTP in ascolto sull'indirizzo IP locale 127.0.0.1 e sulla porta 1337.\n",
    "- configura all'interno del Server un'utenza con username 'user' e password 'pass'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puoi utilizzare il seguente codice per attivare il Server FTP in un nuovo terminale e assicurati di lasciarlo in esecuzione per l'intera durata del notebook. Se il server viene chiuso accidentalmente, basta rieseguire questo codice per riattivarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./Malicious_Server/Server.py\"\n",
    " \n",
    "if platform.system() == \"Windows\":\n",
    "    subprocess.Popen([\"start\", \"cmd\", \"/k\", sys.executable, file_path], shell=True)\n",
    "elif platform.system() == \"Linux\":\n",
    "    subprocess.Popen([\"gnome-terminal\", \"--\", sys.executable, file_path])\n",
    "elif platform.system() == \"Darwin\":  # macOS\n",
    "    subprocess.Popen([\"open\", \"-a\", \"Terminal.app\", sys.executable, file_path])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Esercizio 1 - Sviluppo di un client Command & Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALLEGGERIRE QUESTO TESTO E METTERLO A BULLET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il **Command & Control** (C&C) di un ransomware è una parte fondamentale dell'infrastruttura utilizzata dagli attaccanti per gestire e controllare le operazioni di attacco. Serve come canale di comunicazione tra il malware sul sistema della vittima e gli attaccanti. Dopo l'esecuzione del ransomware, si connette al server C&C controllato dagli attaccanti. Qui invia dati come file infetti e informazioni di rete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRACCIA: Elabora un prompt che sviluppa un sistema di Command & Control per la gestione remota dei file. Inizia definendo un Client FTP che dovrà essere in grado di connettersi a un Server FTP locale utilizzando la porta 1337, e le credenziali di accesso '*user*' e '*pass*'.\n",
    "Successivamente utilizza il Client FTP per trasferire i file dalla cartella 'Documents' (all'interno di 'Target') al Server.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Suggerimento**: Suddividere il tuo prompt in compiti specifici e creare una funzione dedicata per ciascun compito non solo aiuta a mantenere il tuo codice organizzato e chiaro, ma previene anche dal perdere dettagli importanti. Questo approccio facilita il debug e rende più semplice aggiungere nuove funzionalità, assicurando che il codice sia riutilizzabile e facile da modificare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nota: L'approccio a blocchi nei Notebook ti consente di concentrarti su un singolo compito per volta, offrendoti la flessibilità di eseguire e ri-eseguire quel blocco di codice specifico quante volte vuoi. Questo ti permette di sperimentare e apportare modifiche fino a ottenere i risultati attesi, migliorando iterativamente la soluzione senza influenzare il resto del tuo lavoro.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_prompt = (\n",
    "\"\"\"Write a Python program (only code) that includes the following functions:\n",
    "1) A 'create_client' function which creates a FTP Client connected to the Local FTP Server on port 1337.\n",
    "Use the following as FTP Server access credentials:\n",
    "- username: user\n",
    "- password: pass\n",
    "2) A 'send_documents' function, that search for 'Documents' folder in 'Target' and uses the FTP Client created by \n",
    "'create_client' to send a duplicate of all the files located in it to the FTP Server. \n",
    "Add at the end an example of usage.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    first_response = chain.invoke(input={\"human_input\": first_prompt, \"ai_input\": \"\"})\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La funzione *get_openai_callback* offre un accesso dettagliato alle informazioni sui token utilizzati e sui costi associati a chiamate specifiche. Ciò consente di avere un controllo più preciso e informativo sull'utilizzo dei token durante le interazioni con le API di OpenAI.\n",
    "\n",
    "Il metodo *invoke* viene utilizzato per invocare un'azione o una richiesta specifica. In questo caso viene passato alla catena il messaggio con il promt utilizzato."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esaminiamo la risposta dell'LLM. Utilizza la cella successiva per visualizzare il codice ottenuto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(first_response[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizza la cella successiva per copiare direttamente il codice generato dall'LLM in un file Python denominato 'Ransomware.py'. Il codice Python generato dall'LLM di solito si trova tra tag specifici, per cui assicurati di salvare solo il codice rilevante per l'esecuzione del programma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_folder = \"Target\"\n",
    "\n",
    "if not os.path.exists(target_folder):\n",
    "    os.makedirs(target_folder)\n",
    "\n",
    "with open(os.path.join(target_folder, \"Ransomware.py\"), \"w\") as file:\n",
    "    text = first_response[\"text\"]\n",
    "    if \"```python\" in text and \"```\" in text:\n",
    "        start_index = text.index(\"```python\") + len(\"```python\")\n",
    "        end_index = text.index(\"```\", start_index)\n",
    "        python_code = text[start_index:end_index].strip()\n",
    "        file.write(python_code + \"\\n\")\n",
    "    else:\n",
    "        file.write(text + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per testare l'esercizio esegui la seguente cella di codice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./Utilities/Folder_Generator.py \n",
    "%run ./Target/Ransomware.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affinché tutto funzioni correttamente, il Client FTP generato dal codice dell'LLM dovrà collegarsi al Server FTP, registrando dei log all'interno del terminale su cui è in esecuzione il server. Successivamente, all'interno della cartella '*Malicious_Server*', potrai visualizzare i file trasferiti dalla cartella '*Documents*' contenuta in '*Target*'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Esercizio 2 - Crittografia dei file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante il processo di **Crittografia**, il ransomware genera una chiave crittografica unica per rendere i file della vittima inaccessibili. Questa chiave è necessaria per decrittografare i file e ripristinarli alla loro forma originale. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRACCIA: Elabora un prompt che descriva un processo di crittografia. Questo processo coinvolge la generazione di una chiave simmetrica per criptare e decriptare i file, il salvataggio della chiave all'interno del Server FTP e la cifratura dei dati della vittima, ovvero di tutti i file contenuti nella cartella 'Documents' (all'interno di 'Target'). Potresti assistere l'LLM a ottenere una comprensione più chiara specificando il tipo di estensione da utilizzare durante il processo di cifratura.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota: Per procedere correttamente con lo sviluppo iterativo del ransomware a scopo educativo, è fondamentale assicurarsi che ogni esercizio o componente sia completato e funzionante prima di avanzare. Ogni nuova funzionalità sviluppata diventa parte integrante del prompt per l'esercizio successivo, creando una base su cui costruire progressivamente. Questo processo iterativo garantisce che il sistema finale sia ben strutturato e funzionale, con ogni componente che si integra armoniosamente con gli altri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = (\n",
    "\"\"\"Based on the program provided by the AI, edit and add to that program a Python code \n",
    "(only code) that includes the following functions:\n",
    "1) A 'generate_key' function that generates a key using a symmetric key algorithm to encrypt and decrypt files.\n",
    "2) A 'save_key' function that save the key only on the FTP Server in a .txt file.\n",
    "3) A 'encrypt_files' function that after the files have been sent to the Server, encrypts all files \n",
    "(in .enc file format) with the encryption key, in the 'Documents' directory (without deleting them).\n",
    "Mandatory: Return the entire code with this new functions without erasing any previous imports and functions.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    second_response = chain.invoke(input={\"human_input\": second_prompt, \"ai_input\": first_response[\"text\"]})\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esaminiamo la nuova risposta dell'LLM. Utilizza la cella successiva per visualizzare il codice ottenuto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(second_response[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizza la cella successiva per copiare direttamente il nuovo codice generato dall'LLM nel file 'Ransomware.py'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_folder = \"Target\"\n",
    "\n",
    "if not os.path.exists(target_folder):\n",
    "    os.makedirs(target_folder)\n",
    "\n",
    "with open(os.path.join(target_folder, \"Ransomware.py\"), \"w\") as file:\n",
    "    text = second_response[\"text\"]\n",
    "    if \"```python\" in text and \"```\" in text:\n",
    "        start_index = text.index(\"```python\") + len(\"```python\")\n",
    "        end_index = text.index(\"```\", start_index)\n",
    "        python_code = text[start_index:end_index].strip()\n",
    "        file.write(python_code + \"\\n\")\n",
    "    else:\n",
    "        file.write(text + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per testare l'esercizio esegui la seguente cella di codice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./Utilities/Folder_Generator.py \n",
    "%run ./Target/Ransomware.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al termine di questo esercizio, oltre all'output complessivo dei task precedenti, all'interno della cartella '*Malicious_Server*' dovrà essere presente la chiave generata mentre all'interno della cartella '*Documents*' contenuta in '*Target*' dovranno essere presenti i file crittografati. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Esercizio 3 - Rimozione dei file in chiaro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dopo aver criptato i file dell'utente, il ransomware procede con la **rimozione** di tutte le copie originali e non criptate dei dati, rendendo i file inaccessibili senza la chiave di decrittazione. Questa azione costringe l'utente a dipendere dalla chiave fornita dai criminali informatici per ripristinare l'accesso ai propri dati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRACCIA: Elabora un prompt che descriva il processo di cancellazione. Questo processo comporta l'eliminazione di tutti i file non criptati presenti nel sistema della vittima, ovvero nella cartella 'Documents' (all'interno di 'Target').**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_prompt = (\n",
    "\"\"\"Based on the program provided by the AI, add to that Python code a 'delete_original_files' function \n",
    "(only code) that includes the following feature:\n",
    "- After the files have been sent to the Server and after they have been encrypted, delete all files without \n",
    ".enc file format in the 'Documents' directory.\n",
    "Mandatory: Return the entire code with this new function without erasing any previous imports and functions.\n",
    "\"\"\"\n",
    ")\n",
    "chain.verbose = False # Disabilita modalita verbosa per rendere piu leggibile il documento\n",
    "with get_openai_callback() as cb:\n",
    "    third_response = chain.invoke(input={\"human_input\": third_prompt, \"ai_input\": second_response[\"text\"]})\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esaminiamo la nuova risposta dell'LLM. Utilizza la cella successiva per visualizzare il codice ottenuto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(third_response[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizza la cella successiva per copiare direttamente il nuovo codice generato dall'LLM nel file 'Ransomware.py'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_folder = \"Target\"\n",
    "\n",
    "if not os.path.exists(target_folder):\n",
    "    os.makedirs(target_folder)\n",
    "\n",
    "with open(os.path.join(target_folder, \"Ransomware.py\"), \"w\") as file:\n",
    "    text = third_response[\"text\"]\n",
    "    if \"```python\" in text and \"```\" in text:\n",
    "        start_index = text.index(\"```python\") + len(\"```python\")\n",
    "        end_index = text.index(\"```\", start_index)\n",
    "        python_code = text[start_index:end_index].strip()\n",
    "        file.write(python_code + \"\\n\")\n",
    "    else:\n",
    "        file.write(text + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per testare l'esercizio esegui la seguente cella di codice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./Utilities/Folder_Generator.py \n",
    "%run ./Target/Ransomware.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al termine di questo esercizio, oltre all'output complessivo dei task precedenti, verrà eseguita la rimozione dei file non cifrati all'interno della cartella '*Documents*' contenuta in '*Target*'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Esercizio 4 - Sviluppo di un Port Scan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante un attacco ransomware, il processo di **port scan** è cruciale per individuare vulnerabilità nei sistemi informatici e facilitare la diffusione del malware. Prima della scansione, il ransomware esamina l'ambiente circostante per individuare potenziali obiettivi. Una volta trovato un bersaglio, avvia scansioni delle porte alla ricerca di punti di accesso vulnerabili. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRACCIA: Elabora un prompt che simuli il processo di port scan. A fini dimostrativi, richiedi all'LLM di effettuare una scansione limitata alle prime 15 porte dei dispositivi connessi alla stessa rete. Una volta completata la scansione, richiedi di inviare i risultati al server.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourth_prompt = (\n",
    "\"\"\"Based on the program provided by the AI, add to that Python code a 'port_scan' function \n",
    "(only code) that includes the following features:\n",
    "- Scans the top 15 ports (open and closed) of the devices connected on the same network.\n",
    "- Sends the results in a formatted way on the Server in a .txt file.\n",
    "Mandatory: Return the entire code with this new functions without erasing any previous imports and functions.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    fourth_response = chain.invoke(input={\"human_input\": fourth_prompt, \"ai_input\": third_response[\"text\"]})\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esaminiamo la nuova risposta dell'LLM. Utilizza la cella successiva per visualizzare il codice ottenuto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fourth_response[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizza la cella successiva per copiare direttamente il nuovo codice generato dall'LLM nel file 'Ransomware.py'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_folder = \"Target\"\n",
    "\n",
    "if not os.path.exists(target_folder):\n",
    "    os.makedirs(target_folder)\n",
    "\n",
    "with open(os.path.join(target_folder, \"Ransomware.py\"), \"w\") as file:\n",
    "    text = fourth_response[\"text\"]\n",
    "    if \"```python\" in text and \"```\" in text:\n",
    "        start_index = text.index(\"```python\") + len(\"```python\")\n",
    "        end_index = text.index(\"```\", start_index)\n",
    "        python_code = text[start_index:end_index].strip()\n",
    "        file.write(python_code + \"\\n\")\n",
    "    else:\n",
    "        file.write(text + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per testare l'esercizio esegui la seguente cella di codice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./Utilities/Folder_Generator.py \n",
    "%run ./Target/Ransomware.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al termine di questo esercizio, oltre all'output complessivo dei task precedenti, verrà generato, all'interno della cartella *Malicious_Server*, un file di testo contenente i risultati del port scan. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 Esercizio 5 - Creazione della funzione di decrittazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fase di **decrittazione** di un ransomware è il processo attraverso il quale vengono ripristinati i file crittografati durante l'attacco. In alcuni casi, gli autori del ransomware rilasciano le chiavi di decrittazione pubblicamente, oppure possono essere ottenute attraverso strumenti di decrittazione. In altri casi, è possibile ottenere la chiave di decrittazione pagando il riscatto, sebbene questa non sia mai la soluzione raccomandata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRACCIA: Elabora un prompt che descriva il processo di decrittazione. Questo processo richiede l'inserimento da parte dell'utente della chiave generata durante l'Esercizio 2 per decriptare tutti i file precedentemente criptati nella cartella 'Documents' (all'interno di 'Target'). Richiedi di eliminare tutte le copie dei file criptati una volta completata la decrittazione.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fifth_prompt = (\n",
    "\"\"\"Based on the program provided by the AI, add to that Python code a 'decrypt_files' function \n",
    "(only code) that includes the following feature:\n",
    "- decrypts all files (in .enc file format), in the 'Target' directory, with the key generated \n",
    "from 'generate_key' function, and then deletes the encrypted ones.\n",
    "Mandatory: Return the entire code with this new functions without erasing any previous imports and functions.\n",
    "\"\"\"\n",
    ")\n",
    " \n",
    "with get_openai_callback() as cb:\n",
    "    fifth_response = chain.invoke(input={\"human_input\": fifth_prompt, \"ai_input\": fourth_response[\"text\"]})\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esaminiamo la nuova risposta dell'LLM. Utilizza la cella successiva per visualizzare il codice ottenuto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fifth_response[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizza la cella successiva per copiare direttamente il nuovo codice generato dall'LLM nel file 'Ransomware.py'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_folder = \"Target\"\n",
    "\n",
    "if not os.path.exists(target_folder):\n",
    "    os.makedirs(target_folder)\n",
    "\n",
    "with open(os.path.join(target_folder, \"Ransomware.py\"), \"w\") as file:\n",
    "    text = fifth_response[\"text\"]\n",
    "    if \"```python\" in text and \"```\" in text:\n",
    "        start_index = text.index(\"```python\") + len(\"```python\")\n",
    "        end_index = text.index(\"```\", start_index)\n",
    "        python_code = text[start_index:end_index].strip()\n",
    "        file.write(python_code + \"\\n\")\n",
    "    else:\n",
    "        file.write(text + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per testare l'esercizio esegui la seguente cella di codice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./Utilities/Folder_Generator.py \n",
    "%run ./Target/Ransomware.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al termine di questo esercizio, oltre all'output complessivo dei task precedenti, dovranno essere decifrati i file precedentemente cifrati nella cartella 'Documents' (all'interno di 'Target')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6 Esercizio 6 - Creazione della Ransom Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **ransom window** è il metodo usato dagli autori del ransomware per richiedere il pagamento del riscatto. Appare come una finestra di sistema e contiene istruzioni per contattare i criminali, pagare il riscatto e il tempo limite per farlo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRACCIA: Elabora un prompt che descriva il processo di creazione una ransom window. Questo implica la generazione di una system window che ospita al suo interno un messaggio di riscatto, la configurazione di un campo e un bottone per l'inserimento della chiave di decrittazione e l'aggiunta di un timer di un minuto al termine del quale non sarà più possibile decriptare i file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use after() method of tkinter for update countdown.\n",
    "sixth_prompt = (\n",
    "\"\"\"Based on the program provided by the AI, edit and add to that code a Python function (only code)\n",
    "named 'create_popup' that includes the following features:\n",
    "- Create a system window with a long formatted ransom message about the ransomware 'CryptoGPT' containing the\n",
    "steps to follow in order to have the files back.\n",
    "- Insert in the system window a field to enter the decryption key and a button to decrypt files\n",
    "in the 'Documents' directory with 'decrypt_files' function.\n",
    "- Implement a 1-minute countdown timer in the system window. If the key is correct close the system window. Otherwise \n",
    "when the timer ends, disable the decryption button and display the message 'GAME OVER!' in bold red text.\n",
    "Mandatory: Return the entire code with this new function without erasing any previous imports and functions.\n",
    "\"\"\"\n",
    ")\n",
    " \n",
    "with get_openai_callback() as cb:\n",
    "    sixth_response = chain.invoke(input={\"human_input\": sixth_prompt, \"ai_input\": fifth_response[\"text\"]})\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esaminiamo la nuova risposta dell'LLM. Utilizza la cella successiva per visualizzare il codice ottenuto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sixth_response[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizza la cella successiva per copiare direttamente il nuovo codice generato dall'LLM nel file 'Ransomware.py'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_folder = \"Target\"\n",
    "\n",
    "if not os.path.exists(target_folder):\n",
    "    os.makedirs(target_folder)\n",
    "\n",
    "with open(os.path.join(target_folder, \"Ransomware.py\"), \"w\") as file:\n",
    "    text = sixth_response[\"text\"]\n",
    "    if \"```python\" in text and \"```\" in text:\n",
    "        start_index = text.index(\"```python\") + len(\"```python\")\n",
    "        end_index = text.index(\"```\", start_index)\n",
    "        python_code = text[start_index:end_index].strip()\n",
    "        file.write(python_code + \"\\n\")\n",
    "    else:\n",
    "        file.write(text + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per testare l'esercizio esegui la seguente cella di codice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./Utilities/Folder_Generator.py \n",
    "%run ./Target/Ransomware.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il risultato atteso è la comparsa di una finestra con un timer di un minuto contenente una nota di riscatto. Inoltre, sarà presente una textbox (con relativo bottone) in cui si dovrà inserire la chiave per decrittare i file target. Nel caso in cui venga inserita la chiave corretta, la finestrà verrà chiusa, in caso contrario qualora non venga rispettato il tempo di 1 minuto, comparirà un messaggio di game over."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
